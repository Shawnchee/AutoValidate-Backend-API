{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6521f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset \n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "if notebook_dir not in sys.path:\n",
    "    sys.path.append(notebook_dir)\n",
    "\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "OUTPUT_PATH = \"./model/finetuned-embedding-model\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47da554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')\n",
    "QDRANT_URL = os.getenv('QDRANT_URL')\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce753c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a7054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "collection_name = \"car_data_modelbrand\"  \n",
    "\n",
    "# Function to search car brands with typo tolerance\n",
    "def search_car_brand(query, top_k=10):\n",
    "    # Add context to the query to match our embeddings\n",
    "    query_with_context = f\"car brand: {query}\" \n",
    "    query_vector = model.encode(query_with_context)\n",
    "    \n",
    "    # Use query_filter instead of filter parameter\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k * 3,\n",
    "        query_filter={\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"key\": \"vector_type\",\n",
    "                    \"match\": {\n",
    "                        \"value\": \"brand\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Remove duplicates based on car_brand\n",
    "    unique_results_brand = {}\n",
    "    for result in search_result:\n",
    "        car_model = result.payload['car_brand']\n",
    "        if car_model not in unique_results_brand:\n",
    "            unique_results_brand[car_model] = result\n",
    "    \n",
    "    # Return top_k unique results\n",
    "    return list(unique_results_brand.values())[:top_k]\n",
    "\n",
    "\n",
    "# Function to search car models with typo tolerance\n",
    "def search_car_model(query, top_k=10):\n",
    "    # Add generic context to the query to match our embeddings\n",
    "    query_with_context = f\"car model: {query}\"  \n",
    "    query_vector = model.encode(query_with_context)\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k * 3,\n",
    "        query_filter={\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"key\": \"vector_type\",\n",
    "                    \"match\": {\n",
    "                        \"value\": \"model\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Remove duplicates based on car_model\n",
    "    unique_results_model = {}\n",
    "    for result in search_result:\n",
    "        car_model = result.payload['car_model']\n",
    "        if car_model not in unique_results_model:\n",
    "            unique_results_model[car_model] = result\n",
    "    \n",
    "    # Return top_k unique results\n",
    "    return list(unique_results_model.values())[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41a77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process as rapidfuzz_process\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Normalize text to improve matching\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r'[\\-–—_/]', ' ', s)  \n",
    "    s = re.sub(r'\\s+', ' ', s)     \n",
    "    return s  \n",
    "\n",
    "def hybrid_search(query, choices, vector_type=\"brand\", fuzzy_threshold=75, top_k=3, search_model = None):\n",
    "    \"\"\"\n",
    "    Hybrid search that combines RapidFuzz and embeddings:\n",
    "    1. Try fuzzy matching first with 75% threshold (fast + handles typos)\n",
    "    2. If no good fuzzy matches, fall back to embeddings (semantic understanding)\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        choices: List of choices to search against\n",
    "        vector_type: \"brand\" or \"model\"\n",
    "        fuzzy_threshold: Minimum score (0-100) for fuzzy matches\n",
    "        top_k: Number of results to return\n",
    "    \"\"\"\n",
    "    # Normalize query for better matching\n",
    "    query_norm = normalize_text(query)\n",
    "\n",
    "    model_to_use = search_model if search_model is not None else model\n",
    "\n",
    "    \n",
    "    # Adjust scorer based on query characteristics\n",
    "    if ' ' in query_norm or len(query_norm) > 10:\n",
    "        scorer = fuzz.token_sort_ratio  # Better for word order/spacing differences\n",
    "    else:\n",
    "        scorer = fuzz.ratio  # Standard for character-level typos\n",
    "    \n",
    "    # Step 1: Try RapidFuzz first (faster than embeddings)\n",
    "    fuzzy_matches = rapidfuzz_process.extract(\n",
    "        query_norm, \n",
    "        [normalize_text(c) for c in choices],  # Normalize choices too\n",
    "        scorer=scorer,\n",
    "        limit=top_k * 2  # Get more candidates for filtering\n",
    "    )\n",
    "    \n",
    "    # Map normalized choices back to original labels\n",
    "    norm_to_orig = {normalize_text(c): c for c in choices}\n",
    "    fuzzy_matches = [(norm_to_orig.get(match, match), score, idx) for match, score, idx in fuzzy_matches]\n",
    "    \n",
    "    # Filter matches that meet our threshold\n",
    "    good_fuzzy_matches = [(match, score) for match, score, _ in fuzzy_matches if score >= fuzzy_threshold]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # If we have good fuzzy matches, return those\n",
    "    if good_fuzzy_matches:\n",
    "        print(f\"Found {len(good_fuzzy_matches)} good fuzzy matches for '{query}'\")\n",
    "        for match, score in good_fuzzy_matches:\n",
    "            results.append({\n",
    "                \"text\": match,\n",
    "                \"score\": score / 100.0,  # Normalize to 0-1 scale\n",
    "                \"source\": \"fuzzy\"\n",
    "            })\n",
    "    \n",
    "    # Step 2: If not enough good fuzzy matches, use embeddings\n",
    "    if len(results) == 0:\n",
    "        print(f\"No good fuzzy matches above threshold {fuzzy_threshold}, using embeddings\")\n",
    "        \n",
    "        # Use appropriate search function based on vector_type\n",
    "        if vector_type == \"brand\":\n",
    "            # Modify how you call search_car_brand to use the provided model\n",
    "            query_with_context = f\"car brand: {query}\"\n",
    "            query_vector = model_to_use.encode(query_with_context)\n",
    "            \n",
    "            # Call Qdrant directly with the new embedding\n",
    "            search_result = qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=query_vector,\n",
    "                limit=top_k * 3,\n",
    "                query_filter={\"must\": [{\"key\": \"vector_type\", \"match\": {\"value\": \"brand\"}}]}\n",
    "            )\n",
    "            \n",
    "            # Process results as in search_car_brand\n",
    "            embedding_results = []\n",
    "            unique_results = {}\n",
    "            for result in search_result:\n",
    "                car_brand = result.payload['car_brand']\n",
    "                if car_brand not in unique_results:\n",
    "                    unique_results[car_brand] = result\n",
    "                    embedding_results.append(result)\n",
    "        else:  # model\n",
    "            # Similar for model search\n",
    "            query_with_context = f\"car model: {query}\"\n",
    "            query_vector = model_to_use.encode(query_with_context)\n",
    "            \n",
    "            # Call Qdrant directly\n",
    "            search_result = qdrant_client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=query_vector,\n",
    "                limit=top_k * 3,\n",
    "                query_filter={\"must\": [{\"key\": \"vector_type\", \"match\": {\"value\": \"model\"}}]}\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            embedding_results = []\n",
    "            unique_results = {}\n",
    "            for result in search_result:\n",
    "                car_model = result.payload['car_model']\n",
    "                if car_model not in unique_results:\n",
    "                    unique_results[car_model] = result\n",
    "                    embedding_results.append(result)\n",
    "        \n",
    "        # Extract relevant information\n",
    "        for result in embedding_results:\n",
    "            if vector_type == \"brand\":\n",
    "                text = result.payload.get(\"car_brand\")\n",
    "            else:  # model\n",
    "                text = result.payload.get(\"car_model\")\n",
    "                \n",
    "            # Skip if this result is already in our list from fuzzy matching\n",
    "            if any(r[\"text\"] == text for r in results):\n",
    "                continue\n",
    "                \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"score\": result.score,\n",
    "                \"source\": \"embedding\"\n",
    "            })\n",
    "    \n",
    "    # Return top_k results, sorted by score\n",
    "    return sorted(results, key=lambda x: x[\"score\"], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "079951bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training pairs: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>correction</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neesun</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benz</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merz</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mercedesbenz</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toyata</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toyta</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hunda</td>\n",
       "      <td>Honda</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hoonda</td>\n",
       "      <td>Honda</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protan</td>\n",
       "      <td>Proton</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>perodwa</td>\n",
       "      <td>Perodua</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>axla</td>\n",
       "      <td>Axia</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xseventy</td>\n",
       "      <td>X70</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vios</td>\n",
       "      <td>Vios</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vios</td>\n",
       "      <td>Vios</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sivic</td>\n",
       "      <td>Civic</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>civek</td>\n",
       "      <td>Civic</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cityy</td>\n",
       "      <td>City</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x fivty</td>\n",
       "      <td>X50</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>exora</td>\n",
       "      <td>Exora</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           query     correction domain\n",
       "0         neesun         Nissan  brand\n",
       "1           benz  Mercedes-Benz  brand\n",
       "2           merz  Mercedes-Benz  brand\n",
       "3   mercedesbenz  Mercedes-Benz  brand\n",
       "4         toyata         Toyota  brand\n",
       "5          toyta         Toyota  brand\n",
       "6          hunda          Honda  brand\n",
       "7         hoonda          Honda  brand\n",
       "8         protan         Proton  brand\n",
       "9        perodwa        Perodua  brand\n",
       "10          axla           Axia  model\n",
       "11      xseventy            X70  model\n",
       "12          vios           Vios  model\n",
       "13          vios           Vios  model\n",
       "14         sivic          Civic  model\n",
       "15         civek          Civic  model\n",
       "16         cityy           City  model\n",
       "17       x fivty            X50  model\n",
       "18         exora          Exora  model"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Collect training pairs from your examples\n",
    "\n",
    "# Brand test cases\n",
    "brand_typo_pairs = [\n",
    "    (\"neesun\", \"Nissan\"),\n",
    "    (\"benz\", \"Mercedes-Benz\"),\n",
    "    (\"merz\", \"Mercedes-Benz\"),\n",
    "    (\"mercedesbenz\", \"Mercedes-Benz\"),\n",
    "    (\"toyata\", \"Toyota\"),\n",
    "    (\"toyta\", \"Toyota\"),\n",
    "    (\"hunda\", \"Honda\"),\n",
    "    (\"hoonda\", \"Honda\"),\n",
    "    (\"protan\", \"Proton\"),\n",
    "    (\"perodwa\", \"Perodua\"),\n",
    "]\n",
    "\n",
    "# Model test cases - expanded\n",
    "model_typo_pairs = [\n",
    "    (\"axla\", \"Axia\"),\n",
    "    (\"xseventy\", \"X70\"),\n",
    "    (\"vios\", \"Vios\"),\n",
    "    (\"vios\", \"Vios\"),\n",
    "    (\"sivic\", \"Civic\"),\n",
    "    (\"civek\", \"Civic\"),\n",
    "    (\"cityy\", \"City\"),\n",
    "    (\"x fivty\", \"X50\"),\n",
    "    (\"exora\", \"Exora\"),\n",
    "]\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "train_df = pd.DataFrame([\n",
    "    {\"query\": query, \"correction\": correction, \"domain\": \"brand\"} \n",
    "    for query, correction in brand_typo_pairs\n",
    "] + [\n",
    "    {\"query\": query, \"correction\": correction, \"domain\": \"model\"} \n",
    "    for query, correction in model_typo_pairs\n",
    "])\n",
    "\n",
    "print(f\"Total training pairs: {len(train_df)}\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5284d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_examples\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Create training examples\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m train_examples = prepare_training_examples(\u001b[43mtrain_df\u001b[49m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_examples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m training examples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Create sentence-transformers training examples\n",
    "\n",
    "def prepare_training_examples(df):\n",
    "    \"\"\"Create training examples for fine-tuning\"\"\"\n",
    "    train_examples = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        query = row['query']\n",
    "        correction = row['correction']\n",
    "        domain = row['domain']\n",
    "        \n",
    "        # Format with context prefixes matching your ingest format\n",
    "        if domain == \"brand\":\n",
    "            # The typo should map to the correct brand embedding\n",
    "            query_text = f\"car brand: {query}\"\n",
    "            correction_text = f\"car brand: {correction}\"\n",
    "            \n",
    "            # Create training pair (these should map to the same vector)\n",
    "            train_examples.append(InputExample(texts=[query_text, correction_text]))\n",
    "            \n",
    "            # Also add reverse to strengthen the connection\n",
    "            train_examples.append(InputExample(texts=[correction_text, query_text]))\n",
    "            \n",
    "        else:  # model\n",
    "            query_text = f\"car model: {query}\"\n",
    "            correction_text = f\"car model: {correction}\"\n",
    "            \n",
    "            # Create training pair\n",
    "            train_examples.append(InputExample(texts=[query_text, correction_text]))\n",
    "            train_examples.append(InputExample(texts=[correction_text, query_text]))\n",
    "    \n",
    "    return train_examples\n",
    "\n",
    "# Create training examples\n",
    "train_examples = prepare_training_examples(train_df)\n",
    "print(f\"Created {len(train_examples)} training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a5951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING BRAND TYPO DETECTION\n",
      "\n",
      "No good fuzzy matches above threshold 75, using embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aykay\\AppData\\Local\\Temp\\ipykernel_22416\\3121691710.py:77: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'neesun' (expected: Nissan)\n",
      "  1. Perodua (0.9028, embedding)  \n",
      "  2. Nissan (0.9001, embedding) ✓\n",
      "  3. Proton (0.8953, embedding)  \n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'benz' (expected: Mercedes-Benz)\n",
      "  1. Perodua (0.9207, embedding)  \n",
      "  2. Mercedes-Benz (0.9107, embedding) ✓\n",
      "  3. Toyota (0.9030, embedding)  \n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'merz' (expected: Mercedes-Benz)\n",
      "  1. Chery (0.9141, embedding)  \n",
      "  2. Perodua (0.9092, embedding)  \n",
      "  3. Mercedes-Benz (0.8999, embedding) ✓\n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'mercedesbenz' (expected: Mercedes-Benz)\n",
      "  1. Perodua (0.9236, embedding)  \n",
      "  2. Mercedes-Benz (0.9232, embedding) ✓\n",
      "  3. Chery (0.9030, embedding)  \n",
      "------------------------------------------------------------\n",
      "\n",
      "=== BRAND TYPO DETECTION SUMMARY ===\n",
      "Total cases: 4\n",
      "Resolved by fuzzy: 0 (0.0%)\n",
      "Resolved by embeddings: 4 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# 5. Load car data for testing\n",
    "df = pd.read_csv('car_dataset.csv')\n",
    "brand_choices = list(df['car_brand'].unique())\n",
    "model_choices = list(df['car_model'].unique())\n",
    "\n",
    "# Create test cases based on your examples\n",
    "brand_eval_cases = [\n",
    "    (\"neesun\", \"Nissan\"),\n",
    "    (\"benz\", \"Mercedes-Benz\"),\n",
    "    (\"merz\", \"Mercedes-Benz\"),\n",
    "    (\"mercedesbenz\", \"Mercedes-Benz\"),\n",
    "]\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(\"\\nTESTING BRAND TYPO DETECTION\\n\")\n",
    "\n",
    "# Track stats\n",
    "brand_stats = {\"total\": len(brand_eval_cases), \"fuzzy\": 0, \"embedding\": 0}\n",
    "\n",
    "for query, expected in brand_eval_cases:\n",
    "    # Test brand search\n",
    "    results = hybrid_search(query, brand_choices, vector_type=\"brand\", fuzzy_threshold=75, top_k=3, search_model=model)\n",
    "    \n",
    "    # Track which method provided the results\n",
    "    if results and results[0][\"source\"] == \"fuzzy\":\n",
    "        brand_stats[\"fuzzy\"] += 1\n",
    "    elif results:\n",
    "        brand_stats[\"embedding\"] += 1\n",
    "        \n",
    "    # Print results\n",
    "    print(f\"\\nQuery: '{query}' (expected: {expected})\")\n",
    "    for i, res in enumerate(results, 1):\n",
    "        match = \"✓\" if res[\"text\"] == expected else \" \"\n",
    "        print(f\"  {i}. {res['text']} ({res['score']:.4f}, {res['source']}) {match}\")\n",
    "    \n",
    "    # Visual separator\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Print summary stats\n",
    "print(\"\\n=== BRAND TYPO DETECTION SUMMARY ===\")\n",
    "print(f\"Total cases: {brand_stats['total']}\")\n",
    "print(f\"Resolved by fuzzy: {brand_stats['fuzzy']} ({brand_stats['fuzzy']/brand_stats['total']*100:.1f}%)\")\n",
    "print(f\"Resolved by embeddings: {brand_stats['embedding']} ({brand_stats['embedding']/brand_stats['total']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINE-TUNING THE MODEL\n",
      "\n",
      "Training on: cpu\n",
      "Starting fine-tuning for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuned and saved to ./model/finetuned-embedding-model\n"
     ]
    }
   ],
   "source": [
    "# 6. Fine-tune the model\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "print(\"\\nFINE-TUNING THE MODEL\\n\")\n",
    "\n",
    "# Load base model for fine-tuning\n",
    "fine_tune_model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Create data loader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Define loss function - we use contrastive loss to make similar pairs closer\n",
    "train_loss = losses.MultipleNegativesRankingLoss(fine_tune_model)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Fine-tune\n",
    "print(f\"Starting fine-tuning for {EPOCHS} epochs...\")\n",
    "warmup_steps = int(len(train_dataloader) * EPOCHS * 0.1)  # 10% of training as warmup\n",
    "\n",
    "fine_tune_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Model fine-tuned and saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7b4475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING FINE-TUNED MODEL\n",
      "\n",
      "\n",
      "FINE-TUNED MODEL RESULTS\n",
      "\n",
      "No good fuzzy matches above threshold 75, using embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aykay\\AppData\\Local\\Temp\\ipykernel_22416\\3121691710.py:77: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'neesun' (expected: Nissan)\n",
      "  1. Nissan (0.6039, embedding) ✓\n",
      "  2. Toyota (0.4988, embedding)  \n",
      "  3. Mitsubishi (0.4841, embedding)  \n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'benz' (expected: Mercedes-Benz)\n",
      "  1. Mercedes-Benz (0.5434, embedding) ✓\n",
      "  2. Perodua (0.5218, embedding)  \n",
      "  3. BMW (0.4875, embedding)  \n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'merz' (expected: Mercedes-Benz)\n",
      "  1. Mercedes-Benz (0.5536, embedding) ✓\n",
      "  2. Chery (0.5491, embedding)  \n",
      "  3. Perodua (0.5171, embedding)  \n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'mercedesbenz' (expected: Mercedes-Benz)\n",
      "  1. Mercedes-Benz (0.6245, embedding) ✓\n",
      "  2. Perodua (0.5866, embedding)  \n",
      "  3. Chery (0.5607, embedding)  \n",
      "------------------------------------------------------------\n",
      "Found 2 good fuzzy matches for 'axla'\n",
      "\n",
      "Query: 'axla' (expected: Axia)\n",
      "  1. Alza (0.7500, fuzzy)  \n",
      "  2. Axia (0.7500, fuzzy) ✓\n",
      "------------------------------------------------------------\n",
      "No good fuzzy matches above threshold 75, using embeddings\n",
      "\n",
      "Query: 'xseventy' (expected: X70)\n",
      "  1. X70 (0.6537, embedding) ✓\n",
      "  2. X90 (0.6190, embedding)  \n",
      "  3. CX-8 (0.6161, embedding)  \n",
      "------------------------------------------------------------\n",
      "\n",
      "=== FINE-TUNED MODEL DETECTION SUMMARY ===\n",
      "Total test cases: 6\n",
      "\n",
      "Brand cases: 4\n",
      "Resolved by fuzzy: 0 (0.0%)\n",
      "Resolved by embeddings: 4 (100.0%)\n",
      "\n",
      "Model cases: 2\n",
      "Resolved by fuzzy: 1 (50.0%)\n",
      "Resolved by embeddings: 1 (50.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aykay\\AppData\\Local\\Temp\\ipykernel_22416\\3121691710.py:98: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant_client.search(\n"
     ]
    }
   ],
   "source": [
    "# 7. Test with fine-tuned model\n",
    "\n",
    "print(\"\\nTESTING FINE-TUNED MODEL\\n\")\n",
    "\n",
    "# Load the fine-tuned model\n",
    "finetuned_model = SentenceTransformer(OUTPUT_PATH)\n",
    "\n",
    "# Create test cases based on your examples - include both brand and model\n",
    "test_cases = [\n",
    "    # Brand test cases\n",
    "    (\"neesun\", \"Nissan\", \"brand\"),\n",
    "    (\"benz\", \"Mercedes-Benz\", \"brand\"),\n",
    "    (\"merz\", \"Mercedes-Benz\", \"brand\"),\n",
    "    (\"mercedesbenz\", \"Mercedes-Benz\", \"brand\"),\n",
    "    # Model test cases\n",
    "    (\"axla\", \"Axia\", \"model\"),\n",
    "    (\"xseventy\", \"X70\", \"model\"),\n",
    "]\n",
    "\n",
    "# Track stats\n",
    "finetuned_stats = {\"total\": 0, \"brand\": {\"fuzzy\": 0, \"embedding\": 0}, \"model\": {\"fuzzy\": 0, \"embedding\": 0}}\n",
    "\n",
    "# Count total cases by type\n",
    "finetuned_stats[\"brand_total\"] = sum(1 for _, _, domain in test_cases if domain == \"brand\")\n",
    "finetuned_stats[\"model_total\"] = sum(1 for _, _, domain in test_cases if domain == \"model\")\n",
    "finetuned_stats[\"total\"] = len(test_cases)\n",
    "\n",
    "print(\"\\nFINE-TUNED MODEL RESULTS\\n\")\n",
    "\n",
    "for query, expected, domain in test_cases:\n",
    "    # Set choices based on domain\n",
    "    choices = brand_choices if domain == \"brand\" else model_choices\n",
    "    \n",
    "    # Test search with fine-tuned model\n",
    "    results = hybrid_search(\n",
    "        query, choices, vector_type=domain, \n",
    "        fuzzy_threshold=75, top_k=3, search_model=finetuned_model\n",
    "    )\n",
    "    \n",
    "    # Track which method provided the results\n",
    "    if results and results[0][\"source\"] == \"fuzzy\":\n",
    "        finetuned_stats[domain][\"fuzzy\"] += 1\n",
    "    elif results:\n",
    "        finetuned_stats[domain][\"embedding\"] += 1\n",
    "        \n",
    "    # Print results\n",
    "    print(f\"\\nQuery: '{query}' (expected: {expected})\")\n",
    "    for i, res in enumerate(results, 1):\n",
    "        match = \"✓\" if res[\"text\"] == expected else \" \"\n",
    "        print(f\"  {i}. {res['text']} ({res['score']:.4f}, {res['source']}) {match}\")\n",
    "    \n",
    "    # Visual separator\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Print summary stats\n",
    "print(\"\\n=== FINE-TUNED MODEL DETECTION SUMMARY ===\")\n",
    "print(f\"Total test cases: {finetuned_stats['total']}\")\n",
    "\n",
    "print(f\"\\nBrand cases: {finetuned_stats['brand_total']}\")\n",
    "if finetuned_stats['brand_total'] > 0:\n",
    "    print(f\"Resolved by fuzzy: {finetuned_stats['brand']['fuzzy']} ({finetuned_stats['brand']['fuzzy']/finetuned_stats['brand_total']*100:.1f}%)\")\n",
    "    print(f\"Resolved by embeddings: {finetuned_stats['brand']['embedding']} ({finetuned_stats['brand']['embedding']/finetuned_stats['brand_total']*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nModel cases: {finetuned_stats['model_total']}\")\n",
    "if finetuned_stats['model_total'] > 0:\n",
    "    print(f\"Resolved by fuzzy: {finetuned_stats['model']['fuzzy']} ({finetuned_stats['model']['fuzzy']/finetuned_stats['model_total']*100:.1f}%)\")\n",
    "    print(f\"Resolved by embeddings: {finetuned_stats['model']['embedding']} ({finetuned_stats['model']['embedding']/finetuned_stats['model_total']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e8e74",
   "metadata": {},
   "source": [
    "## Retrain the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf10ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Path to your saved model\n",
    "EXISTING_MODEL_PATH = \"./model/finetuned-embedding-model\"\n",
    "OUTPUT_PATH = \"./model/finetuned-embedding-model-v2\"  # New save location\n",
    "\n",
    "# Load the existing model\n",
    "model = SentenceTransformer(EXISTING_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b198e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 16 new training examples\n"
     ]
    }
   ],
   "source": [
    "# Cell to fetch training data from Supabase\n",
    "import pandas as pd\n",
    "from app.api.services.config import SUPABASE_ANON_KEY, SUPABASE_URL\n",
    "from supabase import create_client, Client\n",
    "\n",
    "def fetch_training_data_from_supabase():\n",
    "    \"\"\"Fetch typo correction data from Supabase\"\"\"\n",
    "    try:\n",
    "        # Initialize Supabase client\n",
    "        client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)\n",
    "        \n",
    "        # Fetch all records from typo_training_dataset table\n",
    "        response = client.table(\"typo_training_dataset\").select(\"typo\", \"corrected\", \"domain\").execute()\n",
    "        \n",
    "        if not response.data:\n",
    "            print(\"No training data found in Supabase table\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(response.data)\n",
    "        \n",
    "        # Check required columns exist\n",
    "        required_cols = [\"typo\", \"corrected\", \"domain\"]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Missing required columns in Supabase data: {missing_cols}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Rename columns to match existing code\n",
    "        df = df.rename(columns={\"typo\": \"query\", \"corrected\": \"correction\"})\n",
    "        \n",
    "        print(f\"Successfully fetched {len(df)} training examples from Supabase\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from Supabase: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch data from Supabase\n",
    "supabase_train_df = fetch_training_data_from_supabase()\n",
    "supabase_train_df\n",
    "\n",
    "if not supabase_train_df.empty:\n",
    "    \n",
    "    # Generate training examples from the combined dataset\n",
    "    train_examples = prepare_training_examples(supabase_train_df)\n",
    "    print(f\"Created {len(train_examples)} combined training examples\")\n",
    "    \n",
    "    # Create data loader with the combined examples\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Continue fine-tuning\n",
    "print(f\"Starting additional fine-tuning for 5 epochs...\")\n",
    "warmup_steps = int(len(train_dataloader) * 5 * 0.1)  # 10% of training as warmup\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=5,  # Fewer epochs for continued training\n",
    "    optimizer_params={'lr': 1e-5},\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Model fine-tuned and saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2815ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "Starting additional fine-tuning for 5 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Projects\\vehicle-insurance-backend-api\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuned and saved to ./model/finetuned-embedding-model-v2\n"
     ]
    }
   ],
   "source": [
    "# Create data loader for the new examples\n",
    "train_dataloader = DataLoader(new_train_examples, shuffle=True, batch_size=4)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Continue fine-tuning\n",
    "print(f\"Starting additional fine-tuning for 5 epochs...\")\n",
    "warmup_steps = int(len(train_dataloader) * 5 * 0.1)  # 10% of training as warmup\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=5,  # Fewer epochs for continued training\n",
    "    optimizer_params={'lr': 1e-5},\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Model fine-tuned and saved to {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
